{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6fVpe9qUa8U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "num_points = 1000\n",
        "start_date = '2020-01-01'\n",
        "end_date = '2022-12-31'\n",
        "\n",
        "dates = pd.date_range(start=start_date, end=end_date, periods=num_points)\n",
        "\n",
        "np.random.seed(0)\n",
        "data_values = np.random.normal(loc=0, scale=1, size=num_points)\n",
        "\n",
        "\n",
        "data = pd.DataFrame({'Date': dates, 'Value': data_values})\n",
        "\n",
        "\n",
        "data.to_csv('your_time_series_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "data = pd.read_csv('your_time_series_data.csv')\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data[['value']])\n",
        "\n",
        "def prepare_data(data, time_steps):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_steps):\n",
        "        X.append(data[i:(i + time_steps), 0])\n",
        "        y.append(data[i + time_steps, 0])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "time_steps = 10\n",
        "\n",
        "X, y = prepare_data(scaled_data, time_steps)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=50, return_sequences=True, input_shape=(time_steps, 1)))\n",
        "model.add(LSTM(units=50))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
        "\n",
        "# Evaluate model\n",
        "y_pred = model.predict(X_test)\n",
        "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "y_pred_inv = scaler.inverse_transform(y_pred)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "\n",
        "# Visualize predictions\n",
        "plt.plot(y_test_inv, label='Actual')\n",
        "plt.plot(y_pred_inv, label='Predicted')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Fj7dBe85UlGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess data\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "# Define CNN model\n",
        "def create_model(learning_rate=0.01, optimizer='adam'):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Grid search for hyperparameters\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "param_grid = {'batch_size': [32, 64], 'epochs': [10, 15], 'learning_rate': [0.001, 0.01], 'optimizer': ['adam', 'sgd']}\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(X_train, y_train)\n",
        "\n",
        "# Print results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "\n",
        "# Evaluate model\n",
        "test_loss, test_acc = grid_result.best_estimator_.model.evaluate(X_test, y_test)\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "# Plot training history\n",
        "plt.plot(grid_result.best_estimator_.model.history.history['accuracy'], label='Accuracy')\n",
        "plt.plot(grid_result.best_estimator_.model.history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gMRi6ulhUtEk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}